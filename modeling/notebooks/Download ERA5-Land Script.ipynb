{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the cdsapi package to download the data. We will need xarray to concatenate the data. netCDF4, eccodes, cfgrib, ecmwflibs, and netcdf4 are needed to open the GRIB file and also convert to NetCDF.\n",
    "\n",
    "When you wish to execute shell commands in a jupyter notebook, start the command with \"!\". I am using a virtual environment to run this notebook, so it won't install the packages globally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m pip install cdsapi xarray pandas eccodes cfgrib ecmwflibs netcdf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cdsapi.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of writing this, due to the recent CDS server migrations and slow queues for downloading the data, we can only download a dataset one month at a time. Thus, we will have to loop through every month and year we wish to download. **Important**: Make sure to change the range in 'years_list' to the decades you wish to download. For example, if you're downloading 1951 - 1960, then the range would be range(1951, 1961). In this notebook, I decided to download city data from Ulaanbaatar, Mongolia. The coordinates are 30.2672° N, 97.7431° W, respectively, or 30.3 and -97.7, respectively. **Important**: Since our dataset is specific to land data, it's likely that if the region includes any oceans or large bodies of water, the temperature recorded at those pixels will be inaccurate or missing.\n",
    "\n",
    "The link to the dataset: https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land?tab=overview \n",
    "\n",
    "Dataset name: ERA5-Land hourly data from 1950 to present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.4 47.8 106.4 106.8\n",
      "['2010', '2014', '2018', '2022']\n",
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31']\n",
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30']\n",
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29']\n",
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28']\n"
     ]
    }
   ],
   "source": [
    "years_list = [str(year) for year in range(2010, 2024)]\n",
    "leap_years = [str(year) for year in range(2010, 2024, 4)]\n",
    "\n",
    "make_two_digits = ['01', '02', '03', '04', '05', '06', '07', '08', '09'] # API accepts single digit days in this format\n",
    "\n",
    "thirty_one = make_two_digits + [str(year) for year in range(10, 32)]\n",
    "thirty = make_two_digits + [str(year) for year in range(10, 31)]\n",
    "feb_days_leap = make_two_digits + [str(year) for year in range(10, 30)]\n",
    "feb_days_non_leap = make_two_digits + [str(year) for year in range(10, 29)]\n",
    "\n",
    "months_list = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12'] # API aceepts months in this format\n",
    "month_days = {\n",
    "\t'01':thirty_one,\n",
    "\t'02':feb_days_non_leap,\n",
    "\t'03':thirty_one,\n",
    "\t'04':thirty,\n",
    "\t'05':thirty_one,\n",
    "\t'06':thirty,\n",
    "\t'07':thirty_one,\n",
    "\t'08':thirty_one,\n",
    "\t'09':thirty,\n",
    "\t'10':thirty_one,\n",
    "\t'11':thirty,\n",
    "\t'12':thirty_one,\n",
    "}\n",
    "\n",
    "# Currently downloading data for a model for Mongolia. These are the coords for its capital Ulaanbaatar.\n",
    "city_long = 106.6\n",
    "city_lat = 47.6\n",
    "\n",
    "# Region boundaries for the capital. Will produce a 5x5 grid of values each time step. The spatial resolution of the dataset is 0.1° x 0.1°.\n",
    "bottom_lat = str(round(city_lat - 0.2, 1))\n",
    "top_lat = str(round(city_lat + 0.2, 1))\n",
    "left_long = str(round(city_long - 0.2, 1))\n",
    "right_long = str(round(city_long + 0.2, 1))\n",
    "\n",
    "print(bottom_lat, top_lat, left_long, right_long)\n",
    "print(leap_years)\n",
    "print(thirty_one)\n",
    "print(thirty)\n",
    "print(feb_days_leap)\n",
    "print(feb_days_non_leap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_dataset = []\n",
    "\n",
    "# IMPORTANT: Change 'ds_path' to wherever you originally store the data\n",
    "ds_path = 'C:/Users/sguti/preprocessing/Scorched Earth Data/'\n",
    "\n",
    "for year in years_list:\n",
    "    # Name of the NetCDF file to convert to after concatenating all monthly datasets\n",
    "    nc_filename = ds_path + 'Mongolia_2D_ERA5_' + year + '.nc'\n",
    "    for month in months_list:\n",
    "        # Take care of leap years\n",
    "        if month == '02' and year in leap_years:\n",
    "            month_days['02'] = feb_days_leap\n",
    "        else:\n",
    "            month_days['02'] = feb_days_non_leap\n",
    "        # Name of the raw monthly GRIB file\n",
    "        grib_filename = ds_path + 'Mongolia_2D_ERA5_' + year + '_' + month + '.grib'\n",
    "        c.retrieve(\n",
    "            'reanalysis-era5-land',\n",
    "            {\n",
    "                'format': 'grib',\n",
    "                'variable': [\n",
    "                    '2m_temperature', '2m_dewpoint_temperature', 'surface_pressure', '10m_u_component_of_wind', '10m_v_component_of_wind'\n",
    "                ],\n",
    "                'year': year,\n",
    "                'month': month,\n",
    "                'day': month_days[month],\n",
    "                'time': [\n",
    "                    '00:00', '01:00', '02:00',\n",
    "                    '03:00', '04:00', '05:00',\n",
    "                    '06:00', '07:00', '08:00',\n",
    "                    '09:00', '10:00', '11:00',\n",
    "                    '12:00', '13:00', '14:00',\n",
    "                    '15:00', '16:00', '17:00',\n",
    "                    '18:00', '19:00', '20:00',\n",
    "                    '21:00', '22:00', '23:00',\n",
    "                ],\n",
    "                'area': [\n",
    "                    top_lat, left_long, bottom_lat,\n",
    "                    right_long,\n",
    "                ],\n",
    "            },\n",
    "            grib_filename)\n",
    "        \n",
    "        # Open the GRIB file. Using 'with' will make sure to close the file before execution leaves the 'with' block.\n",
    "        with xr.open_dataset(grib_filename) as ds:\n",
    "            # The GRIB file data contains mostly empty labels [number, surface, valid_time]. We'll drop them before we concatenate with the yearly dataset to save space.\n",
    "            monthly_dataset = ds.drop(['number', 'surface', 'valid_time'], dim=None)\n",
    "            if len(yearly_dataset) == 0:\n",
    "                # If yearly_dataset is empty, there's nothing to concatenate with\n",
    "                yearly_dataset = monthly_dataset\n",
    "            else: \n",
    "                # We will concatenate the two datasets along the time dimension.\n",
    "                yearly_dataset = xr.concat([yearly_dataset, monthly_dataset], dim=\"time\")\n",
    "    # Finally, save the yearly_dataset to a NetCDF file. While GRIB is the native format, GRIB data is generally “messier” than data in a self-describing format, such as NetCDF. \n",
    "    print(\"Storing to... \", nc_filename)\n",
    "    yearly_dataset.to_netcdf(nc_filename)\n",
    "    yearly_dataset = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
